{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "# Library to correct accents, remove emoticons and set sentiment according emoticons\n",
    "import funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load posts data\n",
    "with open('posts/your_posts_1.json') as f:\n",
    "  data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Data format\n",
    "print(type(data))\n",
    "# View content format\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'timestamp': 1548085477, 'attachments': [{'data': [{'media': {'uri': 'photos_and_videos/Lunarojaene20_vUt3ZKqkjQ/49814837_10157026090202070_2927677389464928256_o_10157026090197070.jpg', 'creation_timestamp': 1548085471, 'media_metadata': {'photo_metadata': {'upload_ip': '181.131.165.119'}}, 'title': 'Luna roja - ene 20'}}]}], 'title': 'Isabel Yepes added a new photo.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['timestamp', 'attachments', 'title']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore few posts structure\n",
    "print(data[7976])\n",
    "list(data[7976])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip to the end\n",
    "def right_char(text,char_stop,char_start):\n",
    "    if text.find(char_stop,text.find(char_start)) == -1:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return text[text.find(char_stop,text.find(char_start)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove mentions\n",
    "def filter_mention(content):\n",
    "    temp = content\n",
    "    while temp.find(\"@\") > -1:\n",
    "        if temp.find(\"]\",temp.find(\"@\")) == -1:\n",
    "            temp = \"\"\n",
    "        else:\n",
    "            temp = temp[:temp.find(\"@\")] + temp[temp.find(\"]\",temp.find(\"@\"))+1:]\n",
    "    return temp\n",
    "\n",
    "# Remove urls\n",
    "def filter_url(content):\n",
    "    temp = content\n",
    "    while temp.find(\"http\") > -1:\n",
    "        temp = temp[:temp.find(\"http\")] + right_char(temp,\" \",\"http\")\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill dataframe with posts data with different dict formats and add sentiment using emoticons\n",
    "\n",
    "def fill_dataframe(start,stop,data_array):\n",
    "    posts_array = []\n",
    "    posts_raw_array = []\n",
    "    fechas = []\n",
    "    sentiment = []\n",
    "    for i in range(start, stop):\n",
    "        whole_dict = data_array[i]\n",
    "        post_datetime = datetime.fromtimestamp(whole_dict['timestamp'])\n",
    "        if 'data' in whole_dict:\n",
    "            data_dict = whole_dict['data']\n",
    "            if data_dict:\n",
    "                post = data_dict[0]\n",
    "                if list(post) == ['post']:\n",
    "                    # Save post before changing chars format\n",
    "                    posts_raw_array.append(post['post'])\n",
    "                    # Get post polarity\n",
    "                    sent = funciones.emoticons_sentiment(post['post'])\n",
    "                    sentiment.append(str(sent))\n",
    "                    # Clean post for Spanish and Analysis\n",
    "                    post = funciones.accent_replace(post['post'])\n",
    "                    post = funciones.emoticons_replace(post)\n",
    "                    post = filter_mention(filter_url(post))\n",
    "                    posts_array.append(post)\n",
    "                    fechas.append(str(post_datetime))\n",
    "                else:\n",
    "                    post = \"no_post\"\n",
    "            else:\n",
    "                post = \"no_post\"\n",
    "        elif 'attachments' in whole_dict:\n",
    "            data_dict = whole_dict['attachments']\n",
    "            data_media = data_dict[0]\n",
    "            media_dict = data_media['data']\n",
    "            media_detail = media_dict[0]\n",
    "            media_data = media_detail['media']\n",
    "            if 'description' in media_data:\n",
    "                # Save post before changing chars format\n",
    "                posts_raw_array.append(media_data['description'])\n",
    "                # Get post polarity\n",
    "                sent = funciones.emoticons_sentiment(media_data['description'])\n",
    "                sentiment.append(str(sent))\n",
    "                # Clean post for Spanish and Analysis\n",
    "                post = funciones.accent_replace(media_data['description'])\n",
    "                post = funciones.emoticons_replace(post)\n",
    "                post = filter_mention(filter_url(post))\n",
    "                posts_array.append(post)\n",
    "                fechas.append(str(post_datetime))\n",
    "            elif 'title' in media_data:\n",
    "                # Save post before changing chars format\n",
    "                posts_raw_array.append(media_data['title'])\n",
    "                # Get post polarity\n",
    "                sent = funciones.emoticons_sentiment(media_data['title'])\n",
    "                sentiment.append(str(sent))\n",
    "                # Clean post for Spanish and Analysis\n",
    "                post = funciones.accent_replace(media_data['title'])\n",
    "                post = funciones.emoticons_replace(post)\n",
    "                post = filter_mention(filter_url(post))\n",
    "                posts_array.append(post)\n",
    "                fechas.append(str(post_datetime))\n",
    "            else:\n",
    "                post = \"no_post\"\n",
    "        else:\n",
    "            post = \"no_post\"\n",
    "    df_content = {'dates' : fechas[:], 'content': posts_array[:], 'sentiment': sentiment[:]}\n",
    "    df = pd.DataFrame(df_content)\n",
    "    # Create raw dataframe for saving\n",
    "    df_raw_content = {'dates' : fechas[:], 'content': posts_raw_array[:], 'sentiment': sentiment[:]}\n",
    "    df_raw = pd.DataFrame(df_raw_content)\n",
    "    #print(df_raw)\n",
    "    file_range = '-' + str(start) + '-' + str(stop)\n",
    "    # Save raw data with empty posts stripped\n",
    "    df_raw.to_csv(r'results/post_filtered' + file_range + '.csv', index = False)\n",
    "    # Show dates included in the range\n",
    "    print('Datos Desde: ' + df.loc[0,'dates'] + ' Hasta: ' + df.iloc[-1,0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos Desde: 2020-09-01 20:57:46 Hasta: 2018-10-21 11:45:42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-01 20:57:46</td>\n",
       "      <td>Lindo, con nuestros impuestos.</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-31 02:15:27</td>\n",
       "      <td>Hagamos famosa a Diana Trujillo</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-30 08:02:41</td>\n",
       "      <td>18 años ya. Cuando esté viejita y ya nadie se ...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-30 07:17:53</td>\n",
       "      <td>Desde la casa también meten micos</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-29 20:44:27</td>\n",
       "      <td>El triunfo de la energía estática sobre la fue...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dates                                            content  \\\n",
       "0  2020-09-01 20:57:46                     Lindo, con nuestros impuestos.   \n",
       "1  2020-08-31 02:15:27                    Hagamos famosa a Diana Trujillo   \n",
       "2  2020-08-30 08:02:41  18 años ya. Cuando esté viejita y ya nadie se ...   \n",
       "3  2020-08-30 07:17:53                  Desde la casa también meten micos   \n",
       "4  2020-08-29 20:44:27  El triunfo de la energía estática sobre la fue...   \n",
       "\n",
       "  sentiment  \n",
       "0      none  \n",
       "1      none  \n",
       "2      none  \n",
       "3      none  \n",
       "4         1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of data processed\n",
    "df = fill_dataframe(0,10000,data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "none    4013\n",
       "-1       552\n",
       "1        405\n",
       "0         49\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify frequencies of each category\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El triunfo de la energía estática sobre la fue...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"  ð¨ð´ El concurso, en el que participaro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Les comparto este envivo de IG con Información...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Alguien que Tuitea en vivo y en directo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Debí escibir el nombre de la señora, ya no la ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content sentiment\n",
       "4   El triunfo de la energía estática sobre la fue...         1\n",
       "8   \"  ð¨ð´ El concurso, en el que participaro...         1\n",
       "24  Les comparto este envivo de IG con Información...        -1\n",
       "30      Alguien que Tuitea en vivo y en directo               1\n",
       "32  Debí escibir el nombre de la señora, ya no la ...        -1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy to not modify original data\n",
    "train_df = df[['content','sentiment']].copy()\n",
    "# Remove columns with no sentiment value or too few samples \n",
    "indexNames = train_df[(train_df['sentiment'] == 'none') | (train_df['sentiment'] == '0')].index\n",
    "train_df.drop(indexNames , inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NLP library\n",
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Spacy corpus\n",
    "nlp = spacy.load('es_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "551"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stop Words from es_core_news_sm\n",
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "stopwords_spacy = list(STOP_WORDS)\n",
    "len(stopwords_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerías de aprendizaje\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content      0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificar si hay datos nulos\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~¡¿'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Constante de signos de puntuación\n",
    "import string\n",
    "puntua = string.punctuation + '¡¿'\n",
    "puntua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para limpieza de datos\n",
    "def text_data_cleaning(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if token.lemma_ != \"-PRON-\":\n",
    "            temp = token.lemma_.strip()\n",
    "        else:\n",
    "            temp = token\n",
    "        tokens.append(temp)\n",
    "    \n",
    "    clean_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in stopwords_spacy and token not in puntua:\n",
    "            clean_tokens.append(token)\n",
    "    \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El triunfo de la energía estática sobre la fuerza de gravedad     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['El', 'triunfar', 'energía', 'estático', 'sobrar', 'forzar', 'gravedad']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test cleaning\n",
    "print(train_df['content'][4])\n",
    "text_data_cleaning(train_df['content'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar vectorization library\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tokenize function and create classifier\n",
    "tfidf = TfidfVectorizer(tokenizer = text_data_cleaning)\n",
    "classifier = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datos vectors\n",
    "X = train_df['content']\n",
    "y = train_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((765,), (192,), (765,), (192,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training vector as a portion of data leave the rest for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1909                                                    \"\n",
       "2745                            Ay mi América Latina     \n",
       "1873    She asked for memes with her car photo and she...\n",
       "3054                                                     \n",
       "2737                                                     \n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "clf = Pipeline([('tfidf', tfidf), ('clf', classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define format explicitly to avoid being taken as unknown\n",
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train classifier\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predicted vector from classifier\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.93      0.80       106\n",
      "           1       0.86      0.49      0.62        86\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       192\n",
      "   macro avg       0.77      0.71      0.71       192\n",
      "weighted avg       0.77      0.73      0.72       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify precision obtained\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99,  7],\n",
       "       [44, 42]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nunca habúa visto cómo lucía esta mariposa en su estado de oruga.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict some post sentiments\n",
    "print(df.loc[16,'content'])\n",
    "clf.predict([df.loc[16,'content']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Por esto me toca comprar agua para cocinar en Bogotá, en cualquier momento sin aviso sale amarilla por la llave.  De hecho la cámara la muestra más clara de lo que es.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.loc[160,'content'])\n",
    "clf.predict([df.loc[160,'content']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lindo, con nuestros impuestos.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.loc[0,'content'])\n",
    "clf.predict([df.loc[0,'content']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciencia para todas las personas, no sólo la élite científica\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.loc[9,'content'])\n",
    "clf.predict([df.loc[9,'content']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
